#coding=utf-8
import numpy as np
import xgboost as xgb

# Tree Booster Parameters
param = {'booster' : 'gbtree','max_depth':3, 'eta':1, 'gamma' : 1.0 , 'min_child_weight' : 1 ,'silent':0, 'objective':'binary:logistic' }
# Command Line Parameters
# the number of round to do boosting：迭代次数
num_round = 5
# load file from text file, also binary buffer generated by xgboost
# The path of training data 
dtrain = xgb.DMatrix('agaricus.txt.train')
dtest = xgb.DMatrix('agaricus.txt.test')
# specify validations set to watch performance
# 训练集;测试集展示表展示dtest和dtrain的错误率
watchlist  = [(dtest,'eval'), (dtrain,'train')]
# The messages for evaluation are printed into stderr, so if you want only to log the evaluation progress, simply type
# 按watchlist展示每次迭代的错误率和树枝情况
bst = xgb.train(param, dtrain, num_round, watchlist)
# this is prediction
#preds = bst.predict(dtest)
#labels = dtest.get_label()
#print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))
# save model
#bst.save_model('0002.model')